{"ast":null,"code":"const OpenAIAPI = require('openai');\nconst configuration = new {\n  apiKey: \"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\"\n}();\nconst openai = new OpenAIAPI(configuration);\nexport async function sendMsgToOpenAI(message) {\n  const res = await openai.completions.create({\n    model: 'text-davinchi-003',\n    prompt: message,\n    temperature: 0.7,\n    max_tokens: 256,\n    top_p: 1,\n    frequency_penalty: 0,\n    presence_penalty: 0\n  });\n  return res.choices[0].text;\n}","map":{"version":3,"names":["OpenAIAPI","require","configuration","apiKey","openai","sendMsgToOpenAI","message","res","completions","create","model","prompt","temperature","max_tokens","top_p","frequency_penalty","presence_penalty","choices","text"],"sources":["/Users/wh1skyne/WebstormProjects/ChatAI/Backend/src/openai.js"],"sourcesContent":["const OpenAIAPI = require('openai');\nconst configuration = new ({apiKey: \"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\"});\nconst openai = new OpenAIAPI(configuration);\n\nexport async function sendMsgToOpenAI(message) {\n    const res = await openai.completions.create({\n        model: 'text-davinchi-003',\n        prompt: message,\n        temperature: 0.7,\n        max_tokens: 256,\n        top_p: 1,\n        frequency_penalty: 0,\n        presence_penalty: 0\n    });\n    return res.choices[0].text;\n}"],"mappings":"AAAA,MAAMA,SAAS,GAAGC,OAAO,CAAC,QAAQ,CAAC;AACnC,MAAMC,aAAa,GAAG,IAAK;EAACC,MAAM,EAAE;AAAqD,CAAC,EAAC;AAC3F,MAAMC,MAAM,GAAG,IAAIJ,SAAS,CAACE,aAAa,CAAC;AAE3C,OAAO,eAAeG,eAAeA,CAACC,OAAO,EAAE;EAC3C,MAAMC,GAAG,GAAG,MAAMH,MAAM,CAACI,WAAW,CAACC,MAAM,CAAC;IACxCC,KAAK,EAAE,mBAAmB;IAC1BC,MAAM,EAAEL,OAAO;IACfM,WAAW,EAAE,GAAG;IAChBC,UAAU,EAAE,GAAG;IACfC,KAAK,EAAE,CAAC;IACRC,iBAAiB,EAAE,CAAC;IACpBC,gBAAgB,EAAE;EACtB,CAAC,CAAC;EACF,OAAOT,GAAG,CAACU,OAAO,CAAC,CAAC,CAAC,CAACC,IAAI;AAC9B"},"metadata":{},"sourceType":"module","externalDependencies":[]}