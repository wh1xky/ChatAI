{"ast":null,"code":"import OpenAI from \"openai\";\nconst openai = new OpenAI({\n  apiKey: \"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\",\n  dangerouslyAllowBrowser: true\n});\nexport async function sendMsgToOpenAI(message) {\n  const res = await openai.completions.create({\n    model: 'text-davinci-003',\n    prompt: message,\n    temperature: 0.7,\n    max_tokens: 256,\n    top_p: 1,\n    frequency_penalty: 0,\n    presence_penalty: 0\n  });\n  return res.choices[0].text;\n}","map":{"version":3,"names":["OpenAI","openai","apiKey","dangerouslyAllowBrowser","sendMsgToOpenAI","message","res","completions","create","model","prompt","temperature","max_tokens","top_p","frequency_penalty","presence_penalty","choices","text"],"sources":["/Users/wh1skyne/WebstormProjects/ChatAI/Backend/src/openai.js"],"sourcesContent":["import OpenAI from \"openai\";\nconst openai = new OpenAI ({apiKey: \"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\", dangerouslyAllowBrowser: true});\n\nexport async function sendMsgToOpenAI(message) {\n    const res = await openai.completions.create({\n        model: 'text-davinci-003',\n        prompt: message,\n        temperature: 0.7,\n        max_tokens: 256,\n        top_p: 1,\n        frequency_penalty: 0,\n        presence_penalty: 0\n    });\n    return res.choices[0].text;\n}"],"mappings":"AAAA,OAAOA,MAAM,MAAM,QAAQ;AAC3B,MAAMC,MAAM,GAAG,IAAID,MAAM,CAAE;EAACE,MAAM,EAAE,qDAAqD;EAAEC,uBAAuB,EAAE;AAAI,CAAC,CAAC;AAE1H,OAAO,eAAeC,eAAeA,CAACC,OAAO,EAAE;EAC3C,MAAMC,GAAG,GAAG,MAAML,MAAM,CAACM,WAAW,CAACC,MAAM,CAAC;IACxCC,KAAK,EAAE,kBAAkB;IACzBC,MAAM,EAAEL,OAAO;IACfM,WAAW,EAAE,GAAG;IAChBC,UAAU,EAAE,GAAG;IACfC,KAAK,EAAE,CAAC;IACRC,iBAAiB,EAAE,CAAC;IACpBC,gBAAgB,EAAE;EACtB,CAAC,CAAC;EACF,OAAOT,GAAG,CAACU,OAAO,CAAC,CAAC,CAAC,CAACC,IAAI;AAC9B"},"metadata":{},"sourceType":"module","externalDependencies":[]}