{"ast":null,"code":"const OpenAI = require('openai');\nconst configuration = new Configuration({\n  apiKey: \"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\"\n});\nconst openai = new OpenAIAPI(configuration);\nexport async function sendMsgToOpenAI(message) {\n  const res = await openai.completions.create({\n    model: 'text-davinchi-003',\n    prompt: message,\n    temperature: 0.7,\n    max_tokens: 256,\n    top_p: 1,\n    frequency_penalty: 0,\n    presence_penalty: 0\n  });\n  return res.choices[0].text;\n}","map":{"version":3,"names":["OpenAI","require","configuration","Configuration","apiKey","openai","OpenAIAPI","sendMsgToOpenAI","message","res","completions","create","model","prompt","temperature","max_tokens","top_p","frequency_penalty","presence_penalty","choices","text"],"sources":["/Users/wh1skyne/WebstormProjects/ChatAI/Backend/src/openai.js"],"sourcesContent":["const OpenAI = require('openai');\nconst configuration = new Configuration({apiKey: \"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\"});\nconst openai = new OpenAIAPI(configuration);\n\nexport async function sendMsgToOpenAI(message) {\n    const res = await openai.completions.create({\n        model: 'text-davinchi-003',\n        prompt: message,\n        temperature: 0.7,\n        max_tokens: 256,\n        top_p: 1,\n        frequency_penalty: 0,\n        presence_penalty: 0\n    });\n    return res.choices[0].text;\n}"],"mappings":"AAAA,MAAMA,MAAM,GAAGC,OAAO,CAAC,QAAQ,CAAC;AAChC,MAAMC,aAAa,GAAG,IAAIC,aAAa,CAAC;EAACC,MAAM,EAAE;AAAqD,CAAC,CAAC;AACxG,MAAMC,MAAM,GAAG,IAAIC,SAAS,CAACJ,aAAa,CAAC;AAE3C,OAAO,eAAeK,eAAeA,CAACC,OAAO,EAAE;EAC3C,MAAMC,GAAG,GAAG,MAAMJ,MAAM,CAACK,WAAW,CAACC,MAAM,CAAC;IACxCC,KAAK,EAAE,mBAAmB;IAC1BC,MAAM,EAAEL,OAAO;IACfM,WAAW,EAAE,GAAG;IAChBC,UAAU,EAAE,GAAG;IACfC,KAAK,EAAE,CAAC;IACRC,iBAAiB,EAAE,CAAC;IACpBC,gBAAgB,EAAE;EACtB,CAAC,CAAC;EACF,OAAOT,GAAG,CAACU,OAAO,CAAC,CAAC,CAAC,CAACC,IAAI;AAC9B"},"metadata":{},"sourceType":"module","externalDependencies":[]}